{"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7392164,"sourceType":"datasetVersion","datasetId":4296159}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# WizardOfWikipedia: Knowledge-powered Conversational Agents\n## Authors: \n - Jacopo Di Ventura - jacopo.di.ventura@usi.ch\n - Jury Andrea D'Onofrio - jury.donofrio@usi.ch\n - Matteo Martinoli - matteo.martinoli@usi.ch\n - Roberto Neglia - roberto.neglia@usi.ch\n \n#### Installation and upgrade of libraries","metadata":{}},{"cell_type":"code","source":"%%time \n!pip install hnswlib -q\n!apt-get install espeak-ng -y -q\n!pip install -U torch torchaudio -q\n!pip install TTS -q\n!pip uninstall -y transformers -q\n!pip install transformers==4.22.2 -q\n!pip install --upgrade accelerate -q\n!pip install -U sentence-transformers -q","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Python library imports","metadata":{}},{"cell_type":"code","source":"import json\nimport numpy as np\nimport re\nimport torch\nimport pickle\nimport hnswlib\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\nfrom sentence_transformers import SentenceTransformer, CrossEncoder\nfrom IPython.display import Audio\nfrom IPython.utils import io\nfrom TTS.api import TTS","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Data paths\nMODEL_PATH = \"/kaggle/input/weights/file/test1\"\nEMBEDDINGS_PATH = \"/kaggle/input/weights/embeddings_cache.pickle\"\nINDEX_PATH = \"/kaggle/input/weights/embeddings_index_100.index\"\nPASSAGES_PATH = \"/kaggle/input/weights/passages_list.json\"","metadata":{"execution":{"iopub.status.busy":"2024-01-14T15:35:01.043812Z","iopub.execute_input":"2024-01-14T15:35:01.044578Z","iopub.status.idle":"2024-01-14T15:35:01.049848Z","shell.execute_reply.started":"2024-01-14T15:35:01.044537Z","shell.execute_reply":"2024-01-14T15:35:01.048859Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Device definition\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2024-01-14T15:35:01.053081Z","iopub.execute_input":"2024-01-14T15:35:01.053562Z","iopub.status.idle":"2024-01-14T15:35:01.121438Z","shell.execute_reply.started":"2024-01-14T15:35:01.053512Z","shell.execute_reply":"2024-01-14T15:35:01.120385Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## Pretrained models:\n### Define tokenizer and custom model","metadata":{}},{"cell_type":"code","source":"print('Loading pretrained model...', end=\"\\r\")\ntokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\nmodel = AutoModelForCausalLM.from_pretrained(MODEL_PATH).to(device)\nprint('Loading pretrained model. Done')","metadata":{"execution":{"iopub.status.busy":"2024-01-14T15:35:01.122906Z","iopub.execute_input":"2024-01-14T15:35:01.123348Z","iopub.status.idle":"2024-01-14T15:35:08.173213Z","shell.execute_reply.started":"2024-01-14T15:35:01.123307Z","shell.execute_reply":"2024-01-14T15:35:08.171970Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Loading pretrained model. Done\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Load SentenceTransformer and CrossEncoder models\nIn this code block, two pretrained models are loaded for different natural language processing (NLP) tasks:\n\n1. **Sentence Transformer Model**\n   - `semb_model` is initialized using the 'multi-qa-MiniLM-L6-cos-v1' model. This model is designed for generating embeddings for sentences, which can be useful for various NLP tasks such as similarity analysis and clustering.\n\n2. **Cross-Encoder Model**\n   - `xenc_model` is initialized using the 'cross-encoder/ms-marco-MiniLM-L-6-v2' model. This model is intended for cross-encoder tasks and can be used for tasks that involve ranking or comparing pairs of text.\n\nThese pretrained models provide powerful tools for various NLP applications and tasks.\n","metadata":{}},{"cell_type":"code","source":"print('Loading SentenceTransformer...', end=\"\\r\")\nwith io.capture_output() as captured:\n    semb_model = SentenceTransformer('multi-qa-MiniLM-L6-cos-v1')\nprint('Loading SentenceTransformer. Done')\n    \nprint('Loading CrossEncoder...', end=\"\\r\")\nwith io.capture_output() as captured:    \n    xenc_model = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')\nprint('Loading CrossEncoder. Done')","metadata":{"execution":{"iopub.status.busy":"2024-01-14T15:35:08.174853Z","iopub.execute_input":"2024-01-14T15:35:08.175687Z","iopub.status.idle":"2024-01-14T15:35:14.227889Z","shell.execute_reply.started":"2024-01-14T15:35:08.175648Z","shell.execute_reply":"2024-01-14T15:35:14.226888Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Loading SentenceTransformer. Done\nLoading CrossEncoder. Done\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Load embeddings and HNSW index \n","metadata":{}},{"cell_type":"code","source":"print('Loading embeddings from cache...', end=\"\\r\")\nwith open(EMBEDDINGS_PATH, 'rb') as f:\n    passage_embeddings = pickle.load(f)\nprint('Loading embeddings from cache. Done')\n\nprint('Loading index...', end=\"\\r\")\n# Initialize an HNSW index for efficient similarity search using cosine distance.\nindex = hnswlib.Index(space='cosine', dim=passage_embeddings.size(1))\nindex.load_index(INDEX_PATH)\nprint('Loading index. Done')","metadata":{"execution":{"iopub.status.busy":"2024-01-14T15:35:14.229408Z","iopub.execute_input":"2024-01-14T15:35:14.230138Z","iopub.status.idle":"2024-01-14T15:35:35.662829Z","shell.execute_reply.started":"2024-01-14T15:35:14.230099Z","shell.execute_reply":"2024-01-14T15:35:35.661799Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Loading embeddings from cache. Done\nLoading index. Done\n","output_type":"stream"}]},{"cell_type":"code","source":"# Loading pre-computed passages list\nwith open(PASSAGES_PATH) as f:\n    passages = json.load(f)","metadata":{"execution":{"iopub.status.busy":"2024-01-14T15:35:35.665432Z","iopub.execute_input":"2024-01-14T15:35:35.665893Z","iopub.status.idle":"2024-01-14T15:35:37.138090Z","shell.execute_reply.started":"2024-01-14T15:35:35.665850Z","shell.execute_reply":"2024-01-14T15:35:37.137011Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"### Load text-to-speech model","metadata":{}},{"cell_type":"code","source":"print('Loading Text-to-Speech Model...', end=\"\\r\")\nwith io.capture_output() as captured:\n    tts = TTS('tts_models/en/jenny/jenny', progress_bar=False).to(device)\nprint('Loading Text-to-Speech Model. Done')","metadata":{"execution":{"iopub.status.busy":"2024-01-14T15:35:37.139455Z","iopub.execute_input":"2024-01-14T15:35:37.139813Z","iopub.status.idle":"2024-01-14T15:36:25.189012Z","shell.execute_reply.started":"2024-01-14T15:35:37.139784Z","shell.execute_reply":"2024-01-14T15:36:25.187862Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Loading Text-to-Speech Model. Done\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### `sample_to_string` Function\n\n- The `sample_to_string` function is designed to format the sample information into a string. It includes the context, input text, and the reply using information in the context.\n\n- Args:\n  - `sample` (dict): A dictionary with fields 'context', 'input', and 'target'.\n  - `eos_token` (str): An end-of-sequence token used for separating different parts of the formatted string.\n\n- Returns:\n  - `str`: A formatted string that combines the context, input text, and reply.\n","metadata":{}},{"cell_type":"code","source":"def sample_to_string(sample, eos_token):\n    return f\"context: {sample['context']} {eos_token} input text: {sample['input']} {eos_token} reply using information in the context: {sample['target']} {eos_token}\"","metadata":{"execution":{"iopub.status.busy":"2024-01-14T15:36:25.192599Z","iopub.execute_input":"2024-01-14T15:36:25.192928Z","iopub.status.idle":"2024-01-14T15:36:25.198747Z","shell.execute_reply.started":"2024-01-14T15:36:25.192899Z","shell.execute_reply":"2024-01-14T15:36:25.197223Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"#### `get_response` Function\n\nThis function is defined to generate a response based on a given input message using embeddings and a cross-encoder model.\n\nThe function takes three main inputs:\n  - `message` (str): The input message for which a response is generated.\n  - `index`: An index structure (HNSW index) for efficient similarity search.\n  - `passages` (list): A list of passages to search for responses.\n\n- The function performs the following steps:\n  1. Encodes the input message into an embedding using the Sentence Transformer model (`semb_model`).\n  2. Performs nearest neighbor search using the embedding to retrieve candidate passages (`corpus_ids`).\n  3. Prepares model inputs for cross-encoder predictions using the message and candidate passages.\n  4. Predicts cross-encoder scores for the candidate passages.\n  5. Sorts candidate passages by cross-encoder scores and normalizes the scores.\n  6. Selects passages with scores above a specified threshold (e.g., 0.9).\n  7. Returns the selected passages as the best responses.\n","metadata":{}},{"cell_type":"code","source":"def get_response(message, index, passages):\n    # Encode the input message into an embedding using the Sentence Transformer model\n    message_embedding = semb_model.encode(message, convert_to_tensor=True).cpu()\n    \n    # Perform nearest neighbor search to retrieve candidate passages\n    corpus_ids, _ = index.knn_query(message_embedding, k=64)\n    \n    # Prepare model inputs for cross-encoder predictions\n    model_inputs = [(message, passages[idx]) for idx in corpus_ids[0]]\n    \n    # Predict cross-encoder scores for candidate passages\n    cross_scores = xenc_model.predict(model_inputs, show_progress_bar=False)\n    \n    # Sort candidate passages by cross-encoder scores\n    best_idxs = np.argsort(cross_scores)\n    best_scores = np.sort(cross_scores)\n    \n    # Normalize scores\n    best_scores = (best_scores-np.min(best_scores))/(np.max(best_scores)-np.min(best_scores))\n    \n    # Select passages with scores above > 0.9\n    idxs = []\n    for i in range(len(best_scores)):\n        if best_scores[i] > 0.9:\n            idxs.append(best_idxs[i])\n    \n    # Return the selected passages as the best responses\n    return [passages[corpus_ids[0][idx]] for idx in reversed(idxs)]","metadata":{"execution":{"iopub.status.busy":"2024-01-14T15:36:25.200148Z","iopub.execute_input":"2024-01-14T15:36:25.200530Z","iopub.status.idle":"2024-01-14T15:36:26.086444Z","shell.execute_reply.started":"2024-01-14T15:36:25.200473Z","shell.execute_reply":"2024-01-14T15:36:26.085144Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"#### `text_to_speech` Function\n\nThis function coverts text to speech using a Text-to-Speech (TTS) system.\n\nThe function takes two inputs:\n  - `text` (str): The input text that we want to convert to speech.\n  - `tts`: A TTS object responsible for text-to-speech conversion.\n","metadata":{}},{"cell_type":"code","source":"def text_to_speech(text, tts):\n    # Generate speech from the input text\n    wav = tts.tts(text=text)\n    \n    # Create an audio widget to play the generated speech\n    return Audio(wav, rate=45000, autoplay=True)    ","metadata":{"execution":{"iopub.status.busy":"2024-01-14T15:36:26.088225Z","iopub.execute_input":"2024-01-14T15:36:26.088673Z","iopub.status.idle":"2024-01-14T15:36:26.178608Z","shell.execute_reply.started":"2024-01-14T15:36:26.088633Z","shell.execute_reply":"2024-01-14T15:36:26.177521Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"## Chatbot dialog initialization and interaction:\n\nIn this code block, the bot interacts with the user in a conversation-like manner. Here are the main components of the code:\n\n### Dialog initialization\n\n- `dialog` is initialized using a dictionary. It includes fields for `input` (user's message), `context` (contextual information), and `target` (target response).\n\n- `max_len` determines the length of the conversation.\n\n### User Interaction\n\nIn each turn:\n  - The user's message is read and added to the dialog.\n  - The top passages are retrieved using the `get_response` function based on the user's message.\n  - The returned passages are added to the dialog context.\n  - The dialog is converted to a string and encoded for the model.\n  - The response is generated by the model based on the dialog dictionary.\n  - The generated response is processed and displayed as the chatbot's reply.\n  - The chatbot's response is also converted to speech and played back using text-to-speech conversion.\n","metadata":{}},{"cell_type":"code","source":"# Initialize dialog\ndialog = {\n    \"input\": \"\",\n    \"context\": \"\",\n    \"target\": \"\",\n}\n\n# Maximum dialog length (in turn pairs)\nmax_len = 3\n\nfor i in range(max_len):\n    # Read user message\n    user_message = input(\"> APPRENTICE:\")\n    # Add user message to dialog\n    dialog[\"input\"] = user_message\n\n    # get top passages\n    top_passages = get_response(dialog[\"input\"], index, passages)\n    # add top passages to dialog\n    dialog[\"context\"] = \" \".join(top_passages)\n    \n    # Convert dialog to string\n    input_string = sample_to_string(dialog, tokenizer.eos_token)\n    \n    # Encode input\n    input_encoding = tokenizer(input_string, return_tensors=\"pt\").to(device)\n    \n    # Generate response\n    output_ids = model.generate(\n        input_encoding.input_ids,\n        max_new_tokens=50,\n        do_sample=True,\n        temperature=1.3,\n        num_beams=5,\n        top_k=5,\n        repetition_penalty = 1.2,\n        pad_token_id=tokenizer.eos_token_id,\n    )\n    \n    # Decode response\n    chatbot_response = tokenizer.decode(output_ids[0, input_encoding.input_ids.size(1) :], skip_special_tokens=True)\n    \n    # Fix response string\n    chatbot_response = chatbot_response[41:].rstrip()\n    chatbot_response = re.sub(r'\\s+', ' ', chatbot_response)\n    print(f\"> WIZARD: {chatbot_response}\\n\")\n    print(f\"> CONTEXT USED: {dialog['context']}\")\n    \n    # Text-to-Speech Conversion\n    with io.capture_output() as captured:\n        audio_track = text_to_speech(chatbot_response, tts)\n    display(audio_track)  ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Conclusions:\nIn summary, we have successfully achieved our goal of creating an knowledge-powered conversational agents able to generate an abstract answer based on context retrieved from the user’s input. Additionally, we have effectively augmented our bot with a Text-to-Speech (TTS) system. \n\n## Future works:\nIn order to further improve our system, multiple ideas are possible. For example:\n- Experimenting with alternative pre-trained models.\n- Refining the `sample_to_string` function for improved performance.\n- Exploring different sets of hyper-parameters to optimize system behavior.\n- Investigating the development and integration of a Speech-to-Text system for comprehensive functionality.","metadata":{}}]}